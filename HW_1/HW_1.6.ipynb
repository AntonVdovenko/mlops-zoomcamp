{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan = pd.read_parquet('fhv_tripdata_2021-01.parquet')\n",
    "feb = pd.read_parquet('fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data for January. How many records are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1154112, 7)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Computing duration\n",
    "## Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "## What's the average trip duration in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num              object\n",
       "pickup_datetime           datetime64[ns]\n",
       "dropOff_datetime          datetime64[ns]\n",
       "PUlocationID                     float64\n",
       "DOlocationID                     float64\n",
       "SR_Flag                           object\n",
       "Affiliated_base_number            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan['duration'] = (jan['dropOff_datetime'] - jan['pickup_datetime'])/pd.Timedelta(minutes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.167"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(jan['duration'].mean(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan = jan[(jan.duration >= 1) & (jan.duration <= 60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Missing values\n",
    "## The features we'll use for our model are the pickup and dropoff location IDs.\n",
    "\n",
    "## But they have a lot of missing values there. Let's replace them with \"-1\".\n",
    "\n",
    "## What's the fractions of missing values for the pickup location ID? I.e. fraction of \"-1\"s after you filled the NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num            0\n",
       "pickup_datetime                 0\n",
       "dropOff_datetime                0\n",
       "PUlocationID               927008\n",
       "DOlocationID               147907\n",
       "SR_Flag                   1109826\n",
       "Affiliated_base_number        773\n",
       "duration                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0      927008\n",
       " 221.0      8330\n",
       " 206.0      6797\n",
       " 129.0      5379\n",
       " 115.0      4082\n",
       "           ...  \n",
       " 111.0         5\n",
       " 27.0          4\n",
       " 34.0          3\n",
       " 2.0           2\n",
       " 110.0         1\n",
       "Name: PUlocationID, Length: 262, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan['PUlocationID'].fillna(-1, inplace = True)\n",
    "jan['DOlocationID'].fillna(-1, inplace = True)\n",
    "jan['PUlocationID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8352732770722617"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan['PUlocationID'].value_counts()[-1]/len(jan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. One-hot encoding\n",
    "## Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "## Turn the dataframe into a list of dictionaries\n",
    "## Fit a dictionary vectorizer\n",
    "## Get a feature matrix from it\n",
    "## What's the dimensionality of this matrix? (The number of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jan.loc[:,['PUlocationID','DOlocationID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn X into dict\n",
    "df = df.astype(str)\n",
    "X_dict = df.to_dict(orient='records') # turn each row as key-value pairs\n",
    "# show X_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# instantiate a Dictvectorizer object for X\n",
    "dv_X = DictVectorizer() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1109826x525 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2219652 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply dv_X on X_dict\n",
    "X_encoded = dv_X.fit_transform(X_dict)\n",
    "# show X_encoded\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Training a model\n",
    "## Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "## Train a plain linear regression model with default parameters\n",
    "## Calculate the RMSE of the model on the training data\n",
    "## What's the RMSE on train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.84971459076822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "y = jan['duration'].values\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_encoded,y)\n",
    "print(mse(lr.predict(X_encoded),y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.528519107204405\n"
     ]
    }
   ],
   "source": [
    "print(mse(y,lr.predict(X_encoded))**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Evaluating the model\n",
    "## Now let's apply this model to the validation dataset (Feb 2021).\n",
    "\n",
    "## What's the RMSE on validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df,dv_X):\n",
    "\n",
    "    df['PUlocationID'].fillna(-1, inplace = True)\n",
    "    df['DOlocationID'].fillna(-1, inplace = True)\n",
    "    df['duration'] = (df['dropOff_datetime'] - df['pickup_datetime'])/pd.Timedelta(minutes=1)\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    y = df['duration'].values\n",
    "    df = df.loc[:,['PUlocationID','DOlocationID']]\n",
    "    df = df.astype(str)\n",
    "    X_dict = df.to_dict(orient='records') # turn each row as key-value pairs\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "\n",
    "    X_encoded = dv_X.transform(X_dict)\n",
    "\n",
    "\n",
    "    return X_encoded, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = prepare_df(feb,dv_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<990113x525 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1980223 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.014283137481941"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test,lr.predict(X_test),squared=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a744449aadaec807f66c85c09af1cae3f11a9c3df78f70a1072789401897fb1a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('yolordeepsort')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
